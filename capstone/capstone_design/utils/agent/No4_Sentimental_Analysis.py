# bert_sentiment.py
import json
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from scipy.special import softmax
from collections import Counter
import pandas as pd

# âœ… ê°ì„± ë¶„ì„ ëª¨ë¸ ê²½ë¡œ
NEWS_MODEL = "snunlp/KR-FinBert-SC"

# âœ… í† í¬ë‚˜ì´ì € ë° ëª¨ë¸ ë¡œë”©
news_tokenizer = AutoTokenizer.from_pretrained(NEWS_MODEL)
news_model = AutoModelForSequenceClassification.from_pretrained(NEWS_MODEL)
news_model.eval()

# âœ… ê°ì • ë¼ë²¨ (ë‰´ìŠ¤: 0-ë¶€ì •, 1-ì¤‘ë¦½, 2-ê¸ì •)
news_label_map = {0: "ë¶€ì •", 1: "ì¤‘ë¦½", 2: "ê¸ì •"}

# âœ… ë¶„ì„ í•¨ìˆ˜
def analyze_sentiment(text: str, tokenizer, model, label_map):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, max_length=512)
    with torch.no_grad():
        logits = model(**inputs).logits[0]
    probs = softmax(logits.numpy())
    label_id = int(probs.argmax())
    return label_map[label_id], float(probs[label_id])

# âœ… ê¸°ì‚¬/í† ë¡  ë¦¬ìŠ¤íŠ¸ ê°ì„± ë¶„ì„ ì ìš©
def apply_sentiment_to_articles(articles: list[dict], text_key: str, content_type: str) -> list[dict]:
    results = []
    for article in articles:
        text = article.get(text_key, "").strip()
        if not text:
            continue
        label, score = analyze_sentiment(text, news_tokenizer, news_model, news_label_map)
        article["ê°ì •"] = label
        article["ì ìˆ˜"] = round(score, 4)
        results.append(article)
    return results

# âœ… ê°ì • ê±´ìˆ˜ ì¹´ìš´íŒ…
def count_sentiments(articles: list[dict]) -> Counter:
    return Counter([a["ê°ì •"] for a in articles])

# âœ… ì‹¤í–‰ í…ŒìŠ¤íŠ¸
if __name__ == "__main__":

    # JSON íŒŒì¼ ë¡œë“œ
    with open("JSON/ë™ì„±í™”ì¸í….json", encoding="utf-8") as f:
        data = json.load(f)

    def print_sentiment_list(items, label):
        # ìš”ì•½ ì§‘ê³„
        counts = count_sentiments(items)
        print(f"\nğŸ“Œ [{label}] ê°ì„± ë¶„ì„ ê²°ê³¼ ({len(items)}ê±´)")
        print(f"  ê¸ì •: {counts.get('ê¸ì •',0)}ê±´, ë¶€ì •: {counts.get('ë¶€ì •',0)}ê±´, ì¤‘ë¦½: {counts.get('ì¤‘ë¦½',0)}ê±´\n")
        # ìƒì„¸ ì¶œë ¥
        for i, art in enumerate(items, start=1):
            title = art.get("ì œëª©", "(ì œëª© ì—†ìŒ)")
            body  = art.get("ë³¸ë¬¸", "").replace("\n"," ")
            snippet = body[:80] + ("..." if len(body) > 80 else "")
            print(f"{i}. ì œëª©: {title}")
            print(f"   ë³¸ë¬¸: {snippet}")
            print(f"   ê°ì •: {art['ê°ì •']} (ì ìˆ˜: {art['ì ìˆ˜']:.2f})\n")

    # ê¸°ì—… ë‰´ìŠ¤ê³µì‹œ
    news = apply_sentiment_to_articles(data.get("ë‰´ìŠ¤ê³µì‹œ", []), text_key="ë³¸ë¬¸", content_type="ë‰´ìŠ¤ê³µì‹œ")
    print_sentiment_list(news, "ë‰´ìŠ¤ê³µì‹œ")

    # ì—…ì¢… ë‰´ìŠ¤
    industry = apply_sentiment_to_articles(data.get("ì—…ì¢…ë‰´ìŠ¤", []), text_key="ë³¸ë¬¸", content_type="ì—…ì¢…ë‰´ìŠ¤")
    print_sentiment_list(industry, "ì—…ì¢…ë‰´ìŠ¤")
